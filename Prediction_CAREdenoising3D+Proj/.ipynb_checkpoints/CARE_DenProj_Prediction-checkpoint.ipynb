{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARE restoration and CARE projection predictions ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use in this notebook CARE restoration (can be called CARE denoising also) and CARE projection trained models to perform predictionS of 2D projections of low illuminated stacks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to predict only the restoration of the 3D stacks, or to predict both restoration and projection. We can skip the saving of restored images if we know in advance that the projectcion will be good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we import all the functions we need. We will specify the GPU we wants to use in the last line. We have to check that the GPU is not already use to avoid memory issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import Path, download_and_extract_zip_file, plot_some\n",
    "from csbdeep.io import save_tiff_imagej_compatible\n",
    "from csbdeep.models import CARE, ProjectionCARE\n",
    "from helpers import save_8bit_tiff_imagej_compatible\n",
    "\n",
    "try:\n",
    "    from pathlib import Path\n",
    "    Path().expanduser()\n",
    "except (ImportError, AttributeError):\n",
    "        from pathlib2 import Path\n",
    "\n",
    "try:\n",
    "        import tempfile\n",
    "        tempfile.TemporaryDirectory\n",
    "except (ImportError, AttributeError):\n",
    "       from backports import tempfile    \n",
    "        \n",
    "\n",
    "from skimage import exposure\n",
    "\n",
    "import time\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Processing of the movie**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data we want to process must be conatined in a unique folder. We will give the path to the folder through `basedir`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `basedirResults3D` will be the path were restored stacks will be saved,\n",
    "- `basedirResults2D` wwill be the path were projected stacks will be saved,\n",
    "- `basedirResults3Dextended` will give the prefix of the restored images names, \n",
    "- `basedirResults2Dextended` will give the prefix of the projected images names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Model_Dir` is the path where all the CARE trained models are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basedir='/run/user/1000/gvfs/smb-share:server=isiserver.curie.net,share=u934/equipe_bellaiche/f_bosveld/CARING/shineG4_EcadGFPki_wRNAi_24hL_1' \n",
    "\n",
    "basedirResults3D= basedir + '/Restored'\n",
    "basedirResults2D= basedir + '/Projected'\n",
    "basedirResults3Dextended= basedirResults3D + '/Restored'\n",
    "basedirResults2Dextended= basedirResults2D + '/Projected'\n",
    "\n",
    "Model_Dir='/run/media/sancere/DATA/Lucas_Model_to_use/CARE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we select the model we will use for the prediction and we load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network weights from 'weights_best.h5'.\n"
     ]
    }
   ],
   "source": [
    "RestorationModel = 'CARE_restoration_SpinWideFRAP4_Bin2'\n",
    "ProjectionModel ='CARE_projection_SpinWideFRAP4_Bin2'\n",
    "\n",
    "RestorationModel = CARE(config = None, name = RestorationModel, basedir = Model_Dir)\n",
    "ProjectionModel = ProjectionCARE(config = None, name = ProjectionModel, basedir = Model_Dir) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create the `basedirResults3D` and `basedirResults2D` folders were the predictions will be stored if the folders don't exist yet. We then list all the files with the given file extension (* *choose extenstion*) in the `basedir` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(basedirResults3D).mkdir(exist_ok = True)\n",
    "Path(basedirResults2D).mkdir(exist_ok = True)\n",
    "\n",
    "Raw_path = os.path.join(basedir, '*TIF') #tif or TIF be careful\n",
    "\n",
    "axes = 'ZYX'  #projection axes : 'YX'\n",
    "\n",
    "filesRaw = glob.glob(Raw_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally apply the predictions on each stacks found in the folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3rd line is to avoid to make a CARE prediction (restoration or projection) on a stack that was already processed by the network before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the we know in advance that the model perform well for the predicted dataset, we can convert the predictions into 8bits (`.astype('uint8')`). For the creation of the training set for projection, the restored images has to be converted into 16bits. In the other cases, we won't convert the images with Python but with ImageJ or Fiji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in filesRaw:\n",
    "     if  os.path.exists(fname) == True :\n",
    "            if  os.path.exists(basedirResults3Dextended + '_' + os.path.basename(fname)) == False or os.path.exists(basedirResults2Dextended + '_' + os.path.basename(fname)) == False :\n",
    "                print(fname)\n",
    "                y = imread(fname)\n",
    "                restored = RestorationModel.predict(y, axes, n_tiles = (1,2,4)) #n_tiles is for the decomposition of the image in (z,y,x). (1,2,2) will work with light images. Less tiles we have, faster the calculation is \n",
    "                projection = ProjectionModel.predict(restored, axes, n_tiles = (1,1,1)) #n_tiles is for the decomposition of the image in (z,y,x). There is overlapping in the decomposition wich is managed by the program itself\n",
    "                axes_restored = axes.replace(ProjectionModel.proj_params.axis, '')\n",
    "                restored = restored.astype('uint8') # if prediction and projection running at the same time\n",
    "                #restored = restored.astype('uint16') # if projection training set creation or waiting for a future projection \n",
    "                projection = projection.astype('uint8')\n",
    "                save_tiff_imagej_compatible((basedirResults3Dextended  + '_' +  os.path.basename(fname)) , restored, axes)\n",
    "                save_tiff_imagej_compatible((basedirResults2Dextended + '_' + os.path.basename(fname)) , projection, axes_restored)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
